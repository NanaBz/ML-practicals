{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cbac4ec-71e2-45f4-9568-4210d2fa2ec4",
   "metadata": {},
   "source": [
    "# Week 3 Lecture 2\n",
    "\n",
    "## Classification\n",
    "\n",
    "In this notebook we follow the coding examples from the Week 3 Lecture 1 focusing on the MNIST dataset.\n",
    "\n",
    "We cover:\n",
    "- Loading and exploring MNIST and Visualizing digits\n",
    "- Preparing binary classification targets\n",
    "- Training an SGD classifier and Making predictions\n",
    "- Evaluation: Precision, Recall, Confusion Matrix, ROC\n",
    "- Multiclass Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15faf3b-4e71-4099-8328-ea61d9a3f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455ddce",
   "metadata": {},
   "source": [
    "### Loading the MNIST Dataset\n",
    "\n",
    "Scikit-Learn provides a helper function to fetch popular datasets, including MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "# Explore the returned dictionary\n",
    "print(mnist.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f6d3f",
   "metadata": {},
   "source": [
    "Datasets loaded by Scikit-Learn usually have this structure:\n",
    "- `data`: array with one row per instance, one column per feature\n",
    "- `target`: array with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855a168-3e37-4763-abd3-dcff1f9a1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "print(X.shape) \n",
    "print(y.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473d3c2",
   "metadata": {},
   "source": [
    "Each image is 28×28 pixels flattened into 784 features. Pixel values range from 0 (white) to 255 (black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27579cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most ML algorithms expect numbers, so convert to integer\n",
    "y = y.astype(np.uint8)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed8c15",
   "metadata": {},
   "source": [
    "### Train / Test Split\n",
    "\n",
    "The MNIST dataset is already split: first 60,000 images = training set, last 10,000 = test set.\n",
    "The training set is shuffled, which is good for cross-validation and to avoid order bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83dbcb-5b0e-4185-b068-010c702b4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "print(X_train.shape) \n",
    "print(X_test.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8cfd03",
   "metadata": {},
   "source": [
    "### Training a Binary Classifier (5-detector)\n",
    "\n",
    "We simplify the task: detect whether a digit is 5 or not-5 → binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead9c80-c48d-4a64-861f-de905f1d9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target vectors for binary classification (5 vs not-5)\n",
    "y_train_5 = (y_train == 5)   # True for all 5s, False for others\n",
    "y_test_5  = (y_test == 5)\n",
    "\n",
    "print(y_train_5[:10])   # example: shows True/False array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41427149-bd03-4fcb-8308-330962be6f31",
   "metadata": {},
   "source": [
    "We use **Stochastic Gradient Descent (SGD) classifier** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9c3b1-4bb6-460e-a329-0dea7dc6189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Create and train the classifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6945059d",
   "metadata": {},
   "source": [
    "**Tip**: `random_state` ensures reproducibility because SGD is stochastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0069f7b-6956-41bb-9d56-c19247bbe353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the first digit (which is a 5)\n",
    "some_digit = X_train[0]  \n",
    "print(sgd_clf.predict([some_digit]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc74bf",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Now we dive into **performance measures** for classifiers, starting with cross-validation accuracy, then confusion matrices, precision/recall/F1, the precision/recall trade-off, ROC curves, and some error analysis insights.\n",
    "\n",
    "#### Measuring Accuracy Using Cross-Validation\n",
    "A good way to evaluate the model is using K-fold cross-validation (as in Chapter 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570dfa71-1e04-40f5-aeb2-9e8601a1b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate the SGDClassifier with 3-fold CV\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e0cfe",
   "metadata": {},
   "source": [
    "High accuracy (~95%) — but is it meaningful?\n",
    "\n",
    "**Warning**: Accuracy can be misleading on skewed datasets (only ~10% of digits are 5s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b8e50",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "A better evaluation: count how often the model confuses classes.\n",
    "Use cross_val_predict to get clean predictions (out-of-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get cross-validated predictions (not the same as fit/predict on full train)\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f529816",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Negative', 'Positive']\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Negative / Positive)\")\n",
    "plt.colorbar()\n",
    "ticks = np.arange(len(labels))\n",
    "plt.xticks(ticks, labels)\n",
    "plt.yticks(ticks, labels)\n",
    "\n",
    "annotations = np.array([['TN\\n{}'.format(tn), 'FP\\n{}'.format(fp)],\n",
    "                        ['FN\\n{}'.format(fn), 'TP\\n{}'.format(tp)]])\n",
    "\n",
    "for (ii, jj), text in np.ndenumerate(annotations):\n",
    "    plt.text(jj, ii, text, ha='center', va='center',\n",
    "             color='white' if cm[ii, jj] > cm.max()/2 else 'black', fontsize=12)\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e46f24-4c0b-42ce-9d9b-d7786bfcdcb1",
   "metadata": {},
   "source": [
    "#### Precision, Recall, and F1-Score\n",
    "\n",
    "Precision = TP / (TP + FP) → of detected 5s, how many are real 5s?  \n",
    "Recall = TP / (TP + FN) → of all real 5s, how many were detected?  \n",
    "F1 = harmonic mean of precision and recall (balances both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f672be9b-d71c-4222-a123-c088c5d7c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Precision:\", precision_score(y_train_5, y_train_pred))\n",
    "print(\"Recall:\", recall_score(y_train_5, y_train_pred))\n",
    "print(\"F1-score:\", f1_score(y_train_5, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53c350",
   "metadata": {},
   "source": [
    "Typical values:\n",
    "- Precision: ~0.837 (83.7% of detected 5s are correct)\n",
    "- Recall: ~0.651 (65.1% of real 5s found)\n",
    "- F1: ~0.733 (balance)\n",
    "\n",
    "Precision and recall trade off: higher precision often lowers recall (and vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0a6f2-3506-4df8-bbb5-83b0ccae5ab1",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "\n",
    "Receiver Operating Characteristic curve: plots True Positive Rate (recall) vs. False Positive Rate.\n",
    "Area Under Curve (AUC) summarizes performance (1.0 = perfect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242dc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Obtain decision scores in a cross-validated manner\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # dashed diagonal\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "\n",
    "auc = np.trapz(tpr, fpr)  # approximate AUC\n",
    "plot_roc_curve(fpr, tpr, label=f\"SGD (AUC = {auc:.3f})\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551978ea",
   "metadata": {},
   "source": [
    "## Multiclass Classification\n",
    "\n",
    "Goal: Predict one of 10 classes (digits 0-9) per image.\n",
    "\n",
    "SGDClassifier supports multiclass natively (uses OvR internally: one binary classifier per class, pick highest score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Train on full multiclass targets (y_train with 0-9)\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the example digit\n",
    "print(sgd_clf.predict([some_digit]))  # Should be [5]\n",
    "\n",
    "# See the decision scores for OvR (10 scores, one per class)\n",
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "print(some_digit_scores)\n",
    "\n",
    "# The predicted class is the one with max score\n",
    "print(np.argmax(some_digit_scores))  # 5\n",
    "\n",
    "# List of classes\n",
    "print(sgd_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98abe6-0a4f-4c42-abb8-987ca3b8949b",
   "metadata": {},
   "source": [
    "**OvR vs OvO Strategies**\n",
    "\n",
    "- **One-vs-Rest (OvR)**: Train N binary classifiers (one per class). Pick class with highest score. Simpler, faster training, good for imbalanced data.\n",
    "- **One-vs-One (OvO)**: Train N×(N-1)/2 binary classifiers (every pair). Use voting. More classifiers but each trains on smaller data, can be better for some algorithms like SVM.\n",
    "\n",
    "SVC uses OvO internally (45 classifiers for 10 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f40f2-c1ed-4439-9aa0-463264d49b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVC is slow on full dataset → use small subset for demo\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "svm_clf.fit(X_train[:2000], y_train[:2000])  # 2000 instances for speed\n",
    "\n",
    "# Predict\n",
    "print(svm_clf.predict([some_digit]))\n",
    "\n",
    "# Decision function shape: (1, 45) → one score per pair (OvO)\n",
    "print(svm_clf.decision_function([some_digit]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860c6e7",
   "metadata": {},
   "source": [
    "**Multiclass Evaluation: Confusion Matrix**\n",
    "\n",
    "Use cross-validation for clean predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e50526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cross-validated predictions (takes time)\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\n",
    "\n",
    "# N×N confusion matrix (10×10)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix as heatmap (diagonal = correct, off-diagonal = errors)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ab707",
   "metadata": {},
   "source": [
    "## Multilabel Classification\n",
    "\n",
    "Goal: Assign multiple labels to each instance (e.g., \"is the digit large (>=7)?\" and \"is it odd?\").\n",
    "\n",
    "We use KNeighborsClassifier (supports multilabel natively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddcb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multilabel targets: two binary labels\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]  # shape (60000, 2)\n",
    "\n",
    "print(y_multilabel[:5])  # Example: [False True] for odd small digits, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdf537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "\n",
    "# Predict on example digit (5: not large, odd)\n",
    "print(knn_clf.predict([some_digit]))  # Typically [[False True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120dc9e",
   "metadata": {},
   "source": [
    "**Evaluation**: Use F1-score averaged across labels (macro, weighted, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6560a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Cross-validated predictions (slow on full data, but for illustration)\n",
    "# y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "\n",
    "# Example F1 (macro average)\n",
    "# print(f1_score(y_multilabel, y_train_knn_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13767446",
   "metadata": {},
   "source": [
    "## Multioutput Classification\n",
    "\n",
    "Generalization of multilabel: each \"label\" can have >2 possible values (multiclass outputs).\n",
    "\n",
    "Example (inspired by chapter/PPT): Predict the digit class + parity (even/odd) + a complexity score (e.g., binned number of black pixels).\n",
    "\n",
    "Multioutput models output a vector per instance (e.g., [digit_class, parity_class, complexity_class])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup: add two more outputs\n",
    "# Parity: 0=even, 1=odd (binary but could be multiclass)\n",
    "# Complexity: low/medium/high based on pixel sum (multiclass)\n",
    "\n",
    "pixel_sums = X_train.sum(axis=1)  # total intensity per image\n",
    "complexity_bins = np.digitize(pixel_sums, bins=[np.percentile(pixel_sums, 33), np.percentile(pixel_sums, 66)])\n",
    "# 0=low, 1=med, 2=high\n",
    "\n",
    "y_multioutput = np.c_[y_train, (y_train % 2), complexity_bins]  # shape (60000, 3)\n",
    "\n",
    "# Use a model that supports multioutput, e.g., RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(X_train[:2000], y_multioutput[:2000])  # subset for speed\n",
    "\n",
    "# Predict: returns array of shape (n_samples, n_outputs)\n",
    "some_predictions = forest_clf.predict([some_digit])\n",
    "print(some_predictions)  # e.g., [[5 1 1]] (digit 5, odd, medium complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda9efe",
   "metadata": {},
   "source": [
    "Note: Multioutput is rare in pure classification but useful when tasks are related (e.g., digit + properties). The line blurs with multi-task learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-starter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
